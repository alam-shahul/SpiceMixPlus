{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa207ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import mygene\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2ed8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_LIBD_dataframe = pd.read_csv('../../spatialLIBD/LIBD_sparse_data.csv', header=0, index_col=0, names=['gene', 'spot', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71ad4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIBD_gene_names = pd.read_csv('../../spatialLIBD/LIBD_gene_names.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d290fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-4000...done.\n",
      "querying 4001-5000...done.\n",
      "querying 5001-6000...done.\n",
      "querying 6001-7000...done.\n",
      "querying 7001-8000...done.\n",
      "querying 8001-9000...done.\n",
      "querying 9001-10000...done.\n",
      "querying 10001-11000...done.\n",
      "querying 11001-12000...done.\n",
      "querying 12001-13000...done.\n",
      "querying 13001-14000...done.\n",
      "querying 14001-15000...done.\n",
      "querying 15001-16000...done.\n",
      "querying 16001-17000...done.\n",
      "querying 17001-18000...done.\n",
      "querying 18001-19000...done.\n",
      "querying 19001-20000...done.\n",
      "querying 20001-21000...done.\n",
      "querying 21001-22000...done.\n",
      "querying 22001-23000...done.\n",
      "querying 23001-24000...done.\n",
      "querying 24001-25000...done.\n",
      "querying 25001-26000...done.\n",
      "querying 26001-27000...done.\n",
      "querying 27001-28000...done.\n",
      "querying 28001-29000...done.\n",
      "querying 29001-30000...done.\n",
      "querying 30001-31000...done.\n",
      "querying 31001-32000...done.\n",
      "querying 32001-33000...done.\n",
      "querying 33001-33538...done.\n",
      "Finished.\n",
      "2 input query terms found dup hits:\n",
      "\t[('ENSG00000249981', 2), ('ENSG00000229425', 2)]\n",
      "306 input query terms found no hit:\n",
      "\t['ENSG00000277726', 'ENSG00000271895', 'ENSG00000242349', 'ENSG00000255275', 'ENSG00000225986', 'ENS\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n"
     ]
    }
   ],
   "source": [
    "gene_names = LIBD_gene_names.values.flatten()\n",
    "mg = mygene.MyGeneInfo()\n",
    "gene_symbols = mg.querymany(gene_names, scopes='ensembl.gene', fields=\"symbol\", species=\"human\", as_dataframe=True)\n",
    "gene_symbols = gene_symbols[~gene_symbols.index.duplicated(keep='first')]\n",
    "unmatched_mask = pd.isna(gene_symbols)[\"symbol\"].values\n",
    "processed_gene_symbols = gene_symbols[\"symbol\"].values.astype(str)\n",
    "processed_gene_symbols[unmatched_mask] = gene_symbols.index[unmatched_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae3e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subset_matrix(dataframe, sample_id, coordinates, labels, sample_name):\n",
    "    subset_mask = (sample_id[\"x\"] == sample_name)\n",
    "    subset_index = sample_id[subset_mask].index\n",
    "    subset = dataframe[dataframe[\"spot\"].isin(subset_index)]\n",
    "\n",
    "    subset_coordinates = coordinates[subset_mask.values]\n",
    "    subset_labels = labels[subset_mask.values]\n",
    "    \n",
    "    rows, columns = len(subset[\"spot\"].unique()), dataframe[\"gene\"].max()\n",
    "    \n",
    "    LIBD_data = csr_matrix((subset[\"count\"], (subset[\"spot\"] - subset[\"spot\"].min(), subset[\"gene\"] -1)), shape=(rows, columns)).toarray()\n",
    "    \n",
    "    return LIBD_data, subset_coordinates, subset_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445709c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIBD_sample_ids = pd.read_csv('../../spatialLIBD/LIBD_sample_id.csv', header=0, index_col=0)\n",
    "LIBD_spatial_coordinates = pd.read_csv('../../spatialLIBD/LIBD_coordinates.csv', header=0)\n",
    "LIBD_labels = pd.read_csv('../../spatialLIBD/LIBD_annotations.csv', header=0)\n",
    "\n",
    "sample_names = LIBD_sample_ids[\"x\"].unique()\n",
    "num_samples = len(sample_names)\n",
    "\n",
    "data_directory = Path(\"../../data/spatialLIBD/files\")\n",
    "data_directory.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5c76cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighborhood(spot_locations, method=\"delaunay\", max_neighbors=5, percentile_threshold=95):\n",
    "    \"\"\"Return adjacency matrix in sparse COO format (esssentially).\n",
    "    \"\"\"\n",
    "\n",
    "    num_spots = len(spot_locations)\n",
    "    adjacency_matrix = None\n",
    "    np.random.seed(0)\n",
    "    if method == \"nearest\":\n",
    "        edges=[]\n",
    "        rng = np.random.default_rng()\n",
    "        for vertex in range(num_spots):\n",
    "            neighbors = rng.choice(num_spots, size=num_spots // 2, replace=False)\n",
    "            distances = np.linalg.norm(spot_locations[vertex] - spot_locations[neighbors], axis=1)\n",
    "            top_neighbor_indices = np.argsort(distances)[:max_neighbors]\n",
    "            top_neighbors = neighbors[top_neighbor_indices]\n",
    "            edges.extend([(vertex, neighbor) for neighbor in top_neighbors if vertex != neighbor]) \n",
    "    elif method == \"delaunay\":\n",
    "        triangulation = Delaunay(spot_locations)\n",
    "        indptr, indices = triangulation.vertex_neighbor_vertices\n",
    "        edges = []\n",
    "        for vertex in range(num_spots):\n",
    "            neighbors = indices[indptr[indices[vertex] : indices[vertex + 1]]]\n",
    "            distances = np.linalg.norm(spot_locations[vertex] - spot_locations[neighbors], axis=1)\n",
    "            top_neighbor_indices = np.argsort(distances)[:max_neighbors]   \n",
    "            top_neighbors = neighbors[top_neighbor_indices]\n",
    "            edges.extend([(vertex, neighbor) for neighbor in top_neighbors if vertex != neighbor])\n",
    "\n",
    "    # Trim the top 10% of edges.\n",
    "    distances = np.array([np.linalg.norm(spot_locations[source] - spot_locations[destination]) for (source, destination) in edges])\n",
    "    threshold_mask = (distances < np.percentile(distances, percentile_threshold))\n",
    "    adjacency_matrix = np.array(edges)[threshold_mask]\n",
    "\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead59304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spicemix_input(spot_data, gene_names, coordinates, labels, sample_name, output_directory):\n",
    "    \"\"\"Write input files in correct format for SpiceMix.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    output_directory.mkdir(parents=True, exist_ok=True)\n",
    "    expression_filename = \"expression_{}.txt\".format(sample_name)\n",
    "    neighborhood_filename = \"neighborhood_{}.txt\".format(sample_name)\n",
    "    coordinates_filename = \"coordinates_{}.txt\".format(sample_name)\n",
    "    gene_names_filename = \"genes_{}.txt\".format(sample_name)\n",
    "    labels_filename = \"labels_{}.txt\".format(sample_name)\n",
    "\n",
    "    pd.DataFrame(coordinates).to_csv(Path(output_directory) / coordinates_filename, sep=\"\\t\", header=False, index=False)\n",
    "    pd.DataFrame(labels).to_csv(Path(output_directory) / labels_filename, sep=\"\\t\", header=False, index=False)\n",
    "    \n",
    "    adjacency_matrix = get_neighborhood(coordinates, method=\"nearest\")\n",
    "    pd.DataFrame(adjacency_matrix).to_csv(Path(output_directory) / neighborhood_filename, sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "    total_spot_data = spot_data.sum(axis=1)\n",
    "    transformed_gene_expression_data = np.log(1 + 10**4 * (spot_data / total_spot_data[:, np.newaxis]))\n",
    "    \n",
    "    pd.DataFrame(transformed_gene_expression_data).to_csv(Path(output_directory) / expression_filename, sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "    with open(Path(output_directory) / gene_names_filename, 'w') as filehandle:\n",
    "        for gene in gene_names:\n",
    "            filehandle.write('%s\\n' % gene)\n",
    "            \n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aa66580",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_data = []\n",
    "spot_coordinates = []\n",
    "spot_labels = []\n",
    "for sample_name in sample_names:\n",
    "    sample_spot_data, subset_coordinates, subset_labels = create_subset_matrix(sparse_LIBD_dataframe, LIBD_sample_ids, LIBD_spatial_coordinates, LIBD_labels, sample_name)\n",
    "    spot_data.append(sample_spot_data)\n",
    "    spot_coordinates.append(subset_coordinates)\n",
    "    spot_labels.append(subset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f44d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of HVGs: 3194\n"
     ]
    }
   ],
   "source": [
    "# Filtering genes with less than 20% non-zeros across all samples\n",
    "threshold = 0.1\n",
    "nonzero_mask = np.full(sparse_LIBD_dataframe[\"gene\"].max(), True)\n",
    "for sample_spot_data in spot_data:\n",
    "    sample_nonzero_mask = ((sample_spot_data != 0).sum(axis=0) / len(sample_spot_data) > threshold)\n",
    "    nonzero_mask = (nonzero_mask & sample_nonzero_mask)\n",
    "\n",
    "\n",
    "print(\"Number of HVGs: %d\" % nonzero_mask.sum())\n",
    "filtered_spot_data = [sample_spot_data[:, nonzero_mask] for sample_spot_data in spot_data]\n",
    "filtered_genes = processed_gene_symbols[nonzero_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d68dac40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3194"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_genes)\n",
    "len(np.unique(filtered_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bd6c64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HES4' 'ISG15' 'SDF4' ... 'ND6' 'CYTB' 'LOC102724770']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458375c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of HVGs: 3194\n"
     ]
    }
   ],
   "source": [
    "width = 3\n",
    "height = num_samples // width + (num_samples % width != 0)\n",
    "# width = 1\n",
    "# height = 1\n",
    "fig, axes= plt.subplots(height, width, figsize=(height * 10, width * 10), squeeze=False)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "for coordinates, labels, sample_spot_data, sample_name, ax in zip(spot_coordinates, spot_labels, filtered_spot_data, sample_names, axes.flat):\n",
    "    spot_locations = coordinates[[\"array_row\", \"array_col\"]].values\n",
    "    labels = labels[\"x\"].values.astype(str)\n",
    "\n",
    "    adjacency_matrix = write_spicemix_input(sample_spot_data, filtered_genes, spot_locations, labels, sample_name, data_directory)\n",
    "    \n",
    "    for (source, destination) in adjacency_matrix:\n",
    "        ax.plot([spot_locations[source, 0], spot_locations[destination, 0]],\n",
    "            [spot_locations[source, 1], spot_locations[destination, 1]], color=\"gray\", linewidth=1)\n",
    "\n",
    "    top_ax = ax.twinx()\n",
    "    top_ax.set_zorder(2)\n",
    "    ax.set_zorder(1)\n",
    "        \n",
    "    _, integer_labels = np.unique(labels, return_inverse=True)\n",
    "    x, y = spot_locations.T\n",
    "    ax.scatter(x, y, s=3, c=integer_labels)\n",
    "    ax.set_xlim(ax.get_xlim())\n",
    "    top_ax.set_ylim(ax.get_ylim())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
